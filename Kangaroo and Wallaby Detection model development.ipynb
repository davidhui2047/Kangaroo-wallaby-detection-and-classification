{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7acb5a",
   "metadata": {},
   "source": [
    "# KIT315 Final Project\n",
    "# Kangaroo-wallaby detection\n",
    "(David)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b334c",
   "metadata": {},
   "source": [
    "This project will do Kangaroos and Wallabies detection and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6bb42",
   "metadata": {},
   "source": [
    "## 1. Evironment Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d9931",
   "metadata": {},
   "source": [
    "In this project, the following packages and libraries are used. \n",
    "- Python 3.8\n",
    "- pytorch 1.8.0\n",
    "- torchvision 0.9.0 \n",
    "- cudatoolkit 10.2\n",
    "- pycocotools 2.0.2\n",
    "- numpy 1.20.0\n",
    "- detectron2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d864a2e",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create --name detectron python=3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/facebookresearch/detectron2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c103bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate detectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50054453",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytorch==1.8.0 torchvision==0.9.0 cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd982cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9410e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pycocotools==2.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156474f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71197633",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.20.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06584aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ddd04",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad9b644",
   "metadata": {},
   "source": [
    "For model development, dataset collection is the first step. 700 images for Kangaroos and 700 images for Wallabies are required for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b254e86",
   "metadata": {},
   "source": [
    "The following code will download the first 1000 google image search result of Kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39298d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the library\n",
    "from google_images_download import google_images_download\n",
    "\n",
    "#class instantiation\n",
    "response = google_images_download.googleimagesdownload()   \n",
    "\n",
    "#creating list of arguments\n",
    "kangaroo = {\"keywords\":\"Kangaroo\",\"limit\":1000,\"size\": \"large\",\"format\":\"jpg\",\"chromedriver\":\"./chromedriver.exe\"}   \n",
    "\n",
    "#passing the arguments to the function\n",
    "response.download(kangaroo)   \n",
    "\n",
    "#creating list of arguments\n",
    "wallaby = {\"keywords\":\"Wallaby\",\"limit\":1000,\"size\": \"large\",\"format\":\"jpg\",\"chromedriver\":\"./chromedriver.exe\"}   \n",
    "\n",
    "#passing the arguments to the function\n",
    "response.download(wallaby)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5caab0",
   "metadata": {},
   "source": [
    "For Kangaroo dataset, only around 450 images can be downloaded using the above code. More images will be collected manually on the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288df1a",
   "metadata": {},
   "source": [
    "The following code will download the first 1000 google image search result of Wallaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_images_download import google_images_download   #importing the library\n",
    "\n",
    "response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "\n",
    "arguments = {\"keywords\":\"Wallaby\",\"limit\":1000,\"size\": \"large\",\"format\":\"jpg\",\"chromedriver\":\"./chromedriver.exe\"}   #creating list of arguments\n",
    "response.download(arguments)   #passing the arguments to the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4bf4d7",
   "metadata": {},
   "source": [
    "For Wallaby dataset, only around 450 images can be downloaded using the above code. More images will be collected manually on the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471cfc4b",
   "metadata": {},
   "source": [
    "After dataset collection, dataset annotation is the second step need to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17018e36",
   "metadata": {},
   "source": [
    "In order to label the dataset, graphical image annotation tool *LabelImg* will be used in this project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8ef89",
   "metadata": {},
   "source": [
    "The following code will install LabelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ad4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip3 install labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07662a55",
   "metadata": {},
   "source": [
    "## 3. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00944b2d",
   "metadata": {},
   "source": [
    "The following code find the number of sample and sample that labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a96e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# find number of kangaroo image\n",
    "path, dirs, files = next(os.walk(\"./dataset/all/kangaroo-wallaby/kangaroo\"))\n",
    "num_kangaroo_image = len(files)\n",
    "print(num_kangaroo_image) #966\n",
    "\n",
    "# find number of kangaroo image get labelled\n",
    "path, dirs, files = next(os.walk(\"./dataset/all/kangaroo-wallaby/kangaroo/labels\"))\n",
    "num_kangaroo_image = len(files)\n",
    "print(num_kangaroo_label) #727\n",
    "\n",
    "# find number of wallaby image\n",
    "path, dirs, files = next(os.walk(\"./dataset/all/kangaroo-wallaby/wallaby\"))\n",
    "num_kangaroo_image = len(files)\n",
    "print(num_wallaby_image) #976\n",
    "\n",
    "# find number of wallaby image get labelled\n",
    "path, dirs, files = next(os.walk(\"./dataset/all/kangaroo-wallaby/wallaby/labels\"))\n",
    "num_kangaroo_image = len(files)\n",
    "print(num_wallaby_label) #727"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b023ca9",
   "metadata": {},
   "source": [
    "In the dataset, there are 966 kangaroo images and 976 wallaby image. 727 kangaroo images and 727 wallaby images are labelled. \n",
    "\n",
    "Since the number of images and label images are similar for kangaroo and wallaby so the data are balance.\n",
    "\n",
    "There is no missing values in the dataset\n",
    "\n",
    "The challenge for learning with the dataset is 1454 labeled images may not enough for the model to classify kangaroo and wallaby espically they looks similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ceca39",
   "metadata": {},
   "source": [
    "## 4. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b249d0ea",
   "metadata": {},
   "source": [
    "Since all the images have a very different size, all the images are resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e12af",
   "metadata": {},
   "source": [
    "## 5. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c861b21",
   "metadata": {},
   "source": [
    "In this project, three models will be used for the model development. They are Faster R-CNN, RetinaNet and YOLOv5. All the models provides pre-trained model. Therefore, transfer learning will be applied for model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae700b4",
   "metadata": {},
   "source": [
    "The following code will develop models using Faster R-CNN and RetinaNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fcf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "# import detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.catalog import DatasetCatalog\n",
    "from cocotrainer import CocoTrainer\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"./dataset/train/_annotations.coco.json\", \"./dataset/train\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"./dataset/valid/_annotations.coco.json\", \"./dataset/valid\")\n",
    "register_coco_instances(\"my_dataset_test\", {}, \"./dataset/test/_annotations.coco.json\", \"./dataset/test\")\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "# for d in random.sample(dataset_dicts, 3):\n",
    "#     img = cv2.imread(d[\"file_name\"])\n",
    "#     visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "#     vis = visualizer.draw_dataset_dict(d)\n",
    "#     cv2.imshow('image',vis.get_image()[:, :, ::-1])\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9290db5",
   "metadata": {},
   "source": [
    "The following code will use the pre-trained model of Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caeef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "#from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml\")) # Faster R-CNN\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml\") # Faster R-CNN #training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96046e53",
   "metadata": {},
   "source": [
    "The following code will use the pre-trained model of RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d51e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "#from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_1x.yaml\")) # RetinaNet\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_1x.yaml\")  # RetinaNet #training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 1000 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.SOLVER.STEPS = (1000, 1000)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 #your number of classes + 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"my_dataset_test\", )\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"my_dataset_test\")\n",
    "\n",
    "f = open('./output/config.yaml','w')\n",
    "f.write(cfg.dump())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90daf0",
   "metadata": {},
   "source": [
    "The following code will develop a model using YOLOv5. The code is run on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8821c",
   "metadata": {},
   "source": [
    "Download YOLOv5 and check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5 #download Yolov5 into your repo \n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt #install All the requirements\n",
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "clear_output()\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aadc0b",
   "metadata": {},
   "source": [
    "Link google drive with colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b2d470",
   "metadata": {},
   "source": [
    "Copy dataset from google drive to colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/gdrive/MyDrive/kangaroo-wallaby.zip /content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70337ac3",
   "metadata": {},
   "source": [
    "Unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/kangaroo-wallaby.zip -d /content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf78753",
   "metadata": {},
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 640 --batch 8 --epochs 1000 --data ./data/kangaroo-wallaby.yaml --weights yolov5s.pt --name kangaroo_wallaby_Model --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753f0a9",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbbe54",
   "metadata": {},
   "source": [
    "Training process visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3bf9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard # Tensorboard\n",
    "%tensorboard --logdir runs/train\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c8496",
   "metadata": {},
   "source": [
    "The tensorboards visualize the training process of the models. The model trained using Faster R-CNN pre-trained model has the highest accuracy. Therefore, the model trained using Faster R-CNN pre-trained model is selected as the best model in the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ae41b",
   "metadata": {},
   "source": [
    "## 6. Apply Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fe5b4",
   "metadata": {},
   "source": [
    "In order to test the model, the model will be applied to a video that contain kangaroos and wallabies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7731f",
   "metadata": {},
   "source": [
    "The following code will get the apply the model to a YouTube video that contain kangaroos and wallabies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89bf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import cv2\n",
    "import pafy\n",
    "import glob\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('./output/config.yaml')\n",
    "cfg.MODEL.WEIGHTS = \"./output/model_final.pth\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "print(predictor)\n",
    "MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes = ['kangaroowallaby','kangaroo','wallaby']\n",
    "url = 'https://www.youtube.com/watch?v=fc-Lt6Hsgc0&t'\n",
    "video = pafy.new(url)\n",
    "best = video.getbest(preftype=\"mp4\")\n",
    "capture = cv2.VideoCapture(best.url)\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 25, (640,480))\n",
    "count = 0\n",
    "imageCount = 0\n",
    "while (True):\n",
    "    grabbed, im = capture.read()\n",
    "    if count == 30:\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1)\n",
    "        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        cv2.imshow('', v.get_image()[:, :, ::-1])\n",
    "        out.write(v.get_image()[:, :, ::-1])\n",
    "        count=0\n",
    "        imageCount = imageCount + 1\n",
    "        cv2.imwrite('./image/'+str(imageCount)+'.jpg', v.get_image()[:, :, ::-1])\n",
    "    count = count + 1\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "out.release()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853e51b",
   "metadata": {},
   "source": [
    "Or you can run a file directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python detect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e3653",
   "metadata": {},
   "source": [
    "This is a output of testing the model\n",
    "\n",
    "https://www.youtube.com/watch?v=7Khzb-Nmfwc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
